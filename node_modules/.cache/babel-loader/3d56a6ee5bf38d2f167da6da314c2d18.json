{"ast":null,"code":"import { c as __spreadArray } from './bundle-BQi9-O76.js';\nvar USER_MENTION_PREFIX = '@';\nvar TOKEN_TYPES = {\n  string: 'string',\n  mention: 'mention',\n  url: 'url',\n  undetermined: 'undetermined',\n  markdown: 'markdown'\n};\n\n/**\n * /\\[(.*?)\\]\\((.*?)\\) is for url.\n * /\\*\\*(.*?)\\*\\* for bold.\n */\nvar MarkdownRegex = /\\[(.*?)\\]\\((.*?)\\)|\\*\\*(.*?)\\*\\*/g;\nfunction getUserMentionRegex(mentionedUsers, templatePrefix_) {\n  var templatePrefix = templatePrefix_ || USER_MENTION_PREFIX;\n  return RegExp(\"(\".concat(mentionedUsers.map(function (u) {\n    var userId = u.userId.replace(\n    // If user.id includes these patterns, need to convert it into an escaped one\n    /([.*+?^${}()|[\\]\\\\])/g, '\\\\$1');\n    /**\n     * //{ And //} are also for escaping\n     * because curly braces `{}` are metacharacters in regular expressions used to specify repetition\n     */\n    return \"\".concat(templatePrefix, \"\\\\{\").concat(userId, \"\\\\}\");\n  }).join('|'), \")\"), 'g');\n}\nfunction identifyMentions(_a) {\n  var tokens = _a.tokens,\n    _b = _a.mentionedUsers,\n    mentionedUsers = _b === void 0 ? [] : _b,\n    _c = _a.templatePrefix,\n    templatePrefix = _c === void 0 ? USER_MENTION_PREFIX : _c;\n  if (!(mentionedUsers === null || mentionedUsers === void 0 ? void 0 : mentionedUsers.length)) {\n    return tokens;\n  }\n  var userMentionRegex = getUserMentionRegex(mentionedUsers, templatePrefix);\n  var results = tokens.map(function (token) {\n    // if the token is not undetermined, return it as is\n    // is kinda unnecessary with TS, but just in case\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    var value = token.value;\n    var parts = value.split(userMentionRegex);\n    var tokens = parts.map(function (part) {\n      if (part.match(userMentionRegex)) {\n        var matchedUser = mentionedUsers.find(function (user) {\n          return \"@{\".concat(user === null || user === void 0 ? void 0 : user.userId, \"}\") === part;\n        });\n        var nickname = (matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.nickname) || '(No name)';\n        return {\n          value: nickname,\n          type: TOKEN_TYPES.mention,\n          userId: matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.userId\n        };\n      } else {\n        return {\n          value: part,\n          type: TOKEN_TYPES.undetermined\n        };\n      }\n    });\n    return tokens;\n  }).flat();\n  return results;\n}\nfunction identifyUrlsAndStrings(token) {\n  var URL_REG = /(?:https?:\\/\\/|www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.(xn--)?[a-z]{2,20}\\b([-a-zA-Z0-9@:%_+[\\],.~#?&/=]*[-a-zA-Z0-9@:%_+~#?&/=])*/g;\n  var results = token.map(function (token) {\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    var _a = token.value,\n      value = _a === void 0 ? '' : _a;\n    var matches = Array.from(value.matchAll(URL_REG));\n    var founds = matches.map(function (value) {\n      var _a;\n      var text = value[0];\n      var start = (_a = value.index) !== null && _a !== void 0 ? _a : 0;\n      var end = start + text.length;\n      return {\n        text: text,\n        start: start,\n        end: end\n      };\n    });\n    var items = [{\n      value: value,\n      type: TOKEN_TYPES.string\n    }];\n    var cursor = 0;\n    founds.forEach(function (_a) {\n      var text = _a.text,\n        start = _a.start,\n        end = _a.end;\n      var restText = items.pop().value;\n      var head = restText.slice(0, start - cursor);\n      var mid = text;\n      var tail = restText.slice(end - cursor);\n      if (head.length > 0) items.push({\n        value: head,\n        type: TOKEN_TYPES.string\n      });\n      items.push({\n        value: mid,\n        type: TOKEN_TYPES.url\n      });\n      if (tail.length > 0) items.push({\n        value: tail,\n        type: TOKEN_TYPES.string\n      });\n      cursor = end;\n    });\n    return items;\n  }).flat();\n  return results;\n}\n/**\n * For every string token in the given list of tokens, if the token contains markdowns, the token is split into\n * string tokens and markdown tokens in the original order.\n * Returns a new array tokens.\n * @param tokens\n */\nfunction splitTokensWithMarkdowns(tokens) {\n  var prevTokens = tokens;\n  var newTokens = [];\n  prevTokens.forEach(function (token) {\n    if (token.type === TOKEN_TYPES.mention || token.type === TOKEN_TYPES.markdown) {\n      newTokens.push(token);\n      return;\n    }\n    var rawStr = token.value;\n    // @ts-ignore\n    var matches = Array.from(rawStr.matchAll(MarkdownRegex));\n    var allMatches = matches.map(function (value) {\n      var _a;\n      var text = value[0];\n      var start = (_a = value.index) !== null && _a !== void 0 ? _a : 0;\n      var end = start + text.length;\n      return {\n        text: text,\n        start: start,\n        end: end,\n        groups: value.filter(function (val) {\n          return typeof val === 'string';\n        })\n      };\n    });\n    var restText = rawStr;\n    var cursor = 0;\n    allMatches.forEach(function (_a) {\n      var text = _a.text,\n        start = _a.start,\n        end = _a.end,\n        groups = _a.groups;\n      var left = {\n        type: TOKEN_TYPES.undetermined,\n        value: restText.slice(0, start - cursor)\n      };\n      newTokens.push(left);\n      var markdownType;\n      if (text.startsWith('[')) {\n        markdownType = 'url';\n      } else if (text.startsWith('**')) {\n        markdownType = 'bold';\n      }\n      var mid = {\n        type: TOKEN_TYPES.markdown,\n        markdownType: markdownType,\n        value: text,\n        groups: groups\n      };\n      newTokens.push(mid);\n      restText = rawStr.slice(end);\n      cursor = end;\n    });\n    if (restText) {\n      var right = {\n        type: TOKEN_TYPES.undetermined,\n        value: restText\n      };\n      newTokens.push(right);\n    }\n  });\n  return newTokens;\n}\nfunction combineNearbyStrings(tokens) {\n  var results = tokens.reduce(function (acc, token) {\n    var lastToken = acc[acc.length - 1];\n    if ((lastToken === null || lastToken === void 0 ? void 0 : lastToken.type) === TOKEN_TYPES.string && token.type === TOKEN_TYPES.string) {\n      lastToken.value = \"\".concat(lastToken.value).concat(token.value);\n      return acc;\n    }\n    return __spreadArray(__spreadArray([], acc, true), [token], false);\n  }, []);\n  return results;\n}\n/**\n * Converts text into set of rich tokens\n */\nfunction tokenizeMessage(_a) {\n  var messageText = _a.messageText,\n    _b = _a.mentionedUsers,\n    mentionedUsers = _b === void 0 ? [] : _b,\n    _c = _a.templatePrefix,\n    templatePrefix = _c === void 0 ? USER_MENTION_PREFIX : _c,\n    _d = _a.includeMarkdown,\n    includeMarkdown = _d === void 0 ? false : _d;\n  // mention can be squeezed-in(no-space-between) with other mentions and urls\n  // if no users are mentioned, return the messageText as a single token\n  var partialResult = [{\n    type: TOKEN_TYPES.undetermined,\n    value: messageText\n  }];\n  // order is important because we want to identify mentions first\n  // identifyMentions will return a token with type mention or undetermined\n  var partialWithMentions = identifyMentions({\n    tokens: partialResult,\n    mentionedUsers: mentionedUsers,\n    templatePrefix: templatePrefix\n  });\n  var partialsWithUrlsAndMentions = identifyUrlsAndStrings(includeMarkdown ? splitTokensWithMarkdowns(partialWithMentions) : partialWithMentions);\n  var result = combineNearbyStrings(partialsWithUrlsAndMentions);\n  return result;\n}\nfunction tokenizeMarkdown(_a) {\n  var messageText = _a.messageText;\n  var partialResult = [{\n    type: TOKEN_TYPES.undetermined,\n    value: messageText\n  }];\n  var result = combineNearbyStrings(splitTokensWithMarkdowns(partialResult));\n  return result;\n}\n/**\n * Don't need to use this util in DOM element since the white spaces will be kept as is,\n * but will need if the text is wrapped \\w React.Fragement or </>\n * @link https://sendbird.slack.com/archives/GPGHESTL3/p1681180484341369\n * Or!!! -> convert any space or tab in leading/trailing to nbsp\n * to preserve the leading & trailing white spaces\n */\nfunction getWhiteSpacePreservedText(text) {\n  var NON_BREAKING_SPACE = '\\u00A0';\n  // Split the input string into lines\n  var lines = text.split('\\n');\n  // Process each line and convert leading and trailing white spaces to \"\\u00A0\"\n  var processedLines = lines.map(function (line) {\n    var _a, _b;\n    var leadingWhitespace = ((_a = line.match(/^\\s*/)) === null || _a === void 0 ? void 0 : _a[0]) || '';\n    var trailingWhitespace = ((_b = line.match(/\\s*$/)) === null || _b === void 0 ? void 0 : _b[0]) || '';\n    var convertedLeadingWhitespace = leadingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n    var convertedTrailingWhitespace = trailingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n    return convertedLeadingWhitespace + line.trim() + convertedTrailingWhitespace;\n  });\n  // Combine the processed lines into a new string with \"\\n\"\n  var result = processedLines.join('\\n');\n  return result;\n}\nexport { TOKEN_TYPES as T, USER_MENTION_PREFIX as U, tokenizeMarkdown as a, getWhiteSpacePreservedText as g, tokenizeMessage as t };","map":{"version":3,"names":[],"sources":[],"sourcesContent":["import { c as __spreadArray } from './bundle-BQi9-O76.js';\n\nvar USER_MENTION_PREFIX = '@';\n\nvar TOKEN_TYPES = {\n    string: 'string',\n    mention: 'mention',\n    url: 'url',\n    undetermined: 'undetermined',\n    markdown: 'markdown',\n};\n\n/**\n * /\\[(.*?)\\]\\((.*?)\\) is for url.\n * /\\*\\*(.*?)\\*\\* for bold.\n */\nvar MarkdownRegex = /\\[(.*?)\\]\\((.*?)\\)|\\*\\*(.*?)\\*\\*/g;\nfunction getUserMentionRegex(mentionedUsers, templatePrefix_) {\n    var templatePrefix = templatePrefix_ || USER_MENTION_PREFIX;\n    return RegExp(\"(\".concat(mentionedUsers.map(function (u) {\n        var userId = u.userId.replace(\n        // If user.id includes these patterns, need to convert it into an escaped one\n        /([.*+?^${}()|[\\]\\\\])/g, '\\\\$1');\n        /**\n         * //{ And //} are also for escaping\n         * because curly braces `{}` are metacharacters in regular expressions used to specify repetition\n         */\n        return \"\".concat(templatePrefix, \"\\\\{\").concat(userId, \"\\\\}\");\n    }).join('|'), \")\"), 'g');\n}\nfunction identifyMentions(_a) {\n    var tokens = _a.tokens, _b = _a.mentionedUsers, mentionedUsers = _b === void 0 ? [] : _b, _c = _a.templatePrefix, templatePrefix = _c === void 0 ? USER_MENTION_PREFIX : _c;\n    if (!(mentionedUsers === null || mentionedUsers === void 0 ? void 0 : mentionedUsers.length)) {\n        return tokens;\n    }\n    var userMentionRegex = getUserMentionRegex(mentionedUsers, templatePrefix);\n    var results = tokens.map(function (token) {\n        // if the token is not undetermined, return it as is\n        // is kinda unnecessary with TS, but just in case\n        if (token.type !== TOKEN_TYPES.undetermined) {\n            return token;\n        }\n        var value = token.value;\n        var parts = value.split(userMentionRegex);\n        var tokens = parts.map(function (part) {\n            if (part.match(userMentionRegex)) {\n                var matchedUser = mentionedUsers.find(function (user) { return \"@{\".concat(user === null || user === void 0 ? void 0 : user.userId, \"}\") === part; });\n                var nickname = (matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.nickname) || '(No name)';\n                return { value: nickname, type: TOKEN_TYPES.mention, userId: matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.userId };\n            }\n            else {\n                return { value: part, type: TOKEN_TYPES.undetermined };\n            }\n        });\n        return tokens;\n    }).flat();\n    return results;\n}\nfunction identifyUrlsAndStrings(token) {\n    var URL_REG = /(?:https?:\\/\\/|www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.(xn--)?[a-z]{2,20}\\b([-a-zA-Z0-9@:%_+[\\],.~#?&/=]*[-a-zA-Z0-9@:%_+~#?&/=])*/g;\n    var results = token.map(function (token) {\n        if (token.type !== TOKEN_TYPES.undetermined) {\n            return token;\n        }\n        var _a = token.value, value = _a === void 0 ? '' : _a;\n        var matches = Array.from(value.matchAll(URL_REG));\n        var founds = matches.map(function (value) {\n            var _a;\n            var text = value[0];\n            var start = (_a = value.index) !== null && _a !== void 0 ? _a : 0;\n            var end = start + text.length;\n            return { text: text, start: start, end: end };\n        });\n        var items = [{ value: value, type: TOKEN_TYPES.string }];\n        var cursor = 0;\n        founds.forEach(function (_a) {\n            var text = _a.text, start = _a.start, end = _a.end;\n            var restText = items.pop().value;\n            var head = restText.slice(0, start - cursor);\n            var mid = text;\n            var tail = restText.slice(end - cursor);\n            if (head.length > 0)\n                items.push({ value: head, type: TOKEN_TYPES.string });\n            items.push({ value: mid, type: TOKEN_TYPES.url });\n            if (tail.length > 0)\n                items.push({ value: tail, type: TOKEN_TYPES.string });\n            cursor = end;\n        });\n        return items;\n    }).flat();\n    return results;\n}\n/**\n * For every string token in the given list of tokens, if the token contains markdowns, the token is split into\n * string tokens and markdown tokens in the original order.\n * Returns a new array tokens.\n * @param tokens\n */\nfunction splitTokensWithMarkdowns(tokens) {\n    var prevTokens = tokens;\n    var newTokens = [];\n    prevTokens.forEach(function (token) {\n        if (token.type === TOKEN_TYPES.mention || token.type === TOKEN_TYPES.markdown) {\n            newTokens.push(token);\n            return;\n        }\n        var rawStr = token.value;\n        // @ts-ignore\n        var matches = Array.from(rawStr.matchAll(MarkdownRegex));\n        var allMatches = matches.map(function (value) {\n            var _a;\n            var text = value[0];\n            var start = (_a = value.index) !== null && _a !== void 0 ? _a : 0;\n            var end = start + text.length;\n            return { text: text, start: start, end: end, groups: value.filter(function (val) { return typeof val === 'string'; }) };\n        });\n        var restText = rawStr;\n        var cursor = 0;\n        allMatches.forEach(function (_a) {\n            var text = _a.text, start = _a.start, end = _a.end, groups = _a.groups;\n            var left = {\n                type: TOKEN_TYPES.undetermined,\n                value: restText.slice(0, start - cursor),\n            };\n            newTokens.push(left);\n            var markdownType;\n            if (text.startsWith('[')) {\n                markdownType = 'url';\n            }\n            else if (text.startsWith('**')) {\n                markdownType = 'bold';\n            }\n            var mid = {\n                type: TOKEN_TYPES.markdown,\n                markdownType: markdownType,\n                value: text,\n                groups: groups,\n            };\n            newTokens.push(mid);\n            restText = rawStr.slice(end);\n            cursor = end;\n        });\n        if (restText) {\n            var right = {\n                type: TOKEN_TYPES.undetermined,\n                value: restText,\n            };\n            newTokens.push(right);\n        }\n    });\n    return newTokens;\n}\nfunction combineNearbyStrings(tokens) {\n    var results = tokens.reduce(function (acc, token) {\n        var lastToken = acc[acc.length - 1];\n        if ((lastToken === null || lastToken === void 0 ? void 0 : lastToken.type) === TOKEN_TYPES.string && token.type === TOKEN_TYPES.string) {\n            lastToken.value = \"\".concat(lastToken.value).concat(token.value);\n            return acc;\n        }\n        return __spreadArray(__spreadArray([], acc, true), [token], false);\n    }, []);\n    return results;\n}\n/**\n * Converts text into set of rich tokens\n */\nfunction tokenizeMessage(_a) {\n    var messageText = _a.messageText, _b = _a.mentionedUsers, mentionedUsers = _b === void 0 ? [] : _b, _c = _a.templatePrefix, templatePrefix = _c === void 0 ? USER_MENTION_PREFIX : _c, _d = _a.includeMarkdown, includeMarkdown = _d === void 0 ? false : _d;\n    // mention can be squeezed-in(no-space-between) with other mentions and urls\n    // if no users are mentioned, return the messageText as a single token\n    var partialResult = [{\n            type: TOKEN_TYPES.undetermined,\n            value: messageText,\n        }];\n    // order is important because we want to identify mentions first\n    // identifyMentions will return a token with type mention or undetermined\n    var partialWithMentions = identifyMentions({\n        tokens: partialResult,\n        mentionedUsers: mentionedUsers,\n        templatePrefix: templatePrefix,\n    });\n    var partialsWithUrlsAndMentions = identifyUrlsAndStrings(includeMarkdown\n        ? splitTokensWithMarkdowns(partialWithMentions)\n        : partialWithMentions);\n    var result = combineNearbyStrings(partialsWithUrlsAndMentions);\n    return result;\n}\nfunction tokenizeMarkdown(_a) {\n    var messageText = _a.messageText;\n    var partialResult = [{\n            type: TOKEN_TYPES.undetermined,\n            value: messageText,\n        }];\n    var result = combineNearbyStrings(splitTokensWithMarkdowns(partialResult));\n    return result;\n}\n/**\n * Don't need to use this util in DOM element since the white spaces will be kept as is,\n * but will need if the text is wrapped \\w React.Fragement or </>\n * @link https://sendbird.slack.com/archives/GPGHESTL3/p1681180484341369\n * Or!!! -> convert any space or tab in leading/trailing to nbsp\n * to preserve the leading & trailing white spaces\n */\nfunction getWhiteSpacePreservedText(text) {\n    var NON_BREAKING_SPACE = '\\u00A0';\n    // Split the input string into lines\n    var lines = text.split('\\n');\n    // Process each line and convert leading and trailing white spaces to \"\\u00A0\"\n    var processedLines = lines.map(function (line) {\n        var _a, _b;\n        var leadingWhitespace = ((_a = line.match(/^\\s*/)) === null || _a === void 0 ? void 0 : _a[0]) || '';\n        var trailingWhitespace = ((_b = line.match(/\\s*$/)) === null || _b === void 0 ? void 0 : _b[0]) || '';\n        var convertedLeadingWhitespace = leadingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n        var convertedTrailingWhitespace = trailingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n        return convertedLeadingWhitespace + line.trim() + convertedTrailingWhitespace;\n    });\n    // Combine the processed lines into a new string with \"\\n\"\n    var result = processedLines.join('\\n');\n    return result;\n}\n\nexport { TOKEN_TYPES as T, USER_MENTION_PREFIX as U, tokenizeMarkdown as a, getWhiteSpacePreservedText as g, tokenizeMessage as t };\n//# sourceMappingURL=bundle-GUbI4JcD.js.map\n"],"mappings":"","ignoreList":[]},"metadata":{},"sourceType":"module"}